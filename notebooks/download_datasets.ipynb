{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8433ad7a",
   "metadata": {},
   "source": [
    "## Imports & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45cc49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import snapshot_download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a70a06be",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/root/workspace/agentic-nlp-rl/data/raw\"\n",
    "\n",
    "PATHS = {\n",
    "    \"meld\": f\"{BASE_DIR}/meld\",\n",
    "    \"mpdd\": f\"{BASE_DIR}/mpdd\",\n",
    "    \"alfworld\": f\"{BASE_DIR}/alfworld\",\n",
    "    \"scienceworld\": f\"{BASE_DIR}/scienceworld\",\n",
    "    \"textworld\": f\"{BASE_DIR}/textworld\",\n",
    "}\n",
    "\n",
    "for p in PATHS.values():\n",
    "    os.makedirs(p, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a9096c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parents[0]  # works when running from notebooks/\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558886dc",
   "metadata": {},
   "source": [
    "## MELD (Emotion-Aware Dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95eb5670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab70782ab77644c6ae9651596d163497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45661c80ef5845ff91b8d1fc05ff0991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683983e9c84e4e6eb4074a1139b4f9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2666bc94ff564f56a01202c7744c2de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/9989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a38f4bcf084bc5b188689d186c76f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1109 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f2483120aa46c59055e8019959d9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2610 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Sr No.', 'Utterance', 'Speaker', 'Emotion', 'Sentiment', 'Dialogue_ID', 'Utterance_ID', 'Season', 'Episode', 'StartTime', 'EndTime'],\n",
      "        num_rows: 9989\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Sr No.', 'Utterance', 'Speaker', 'Emotion', 'Sentiment', 'Dialogue_ID', 'Utterance_ID', 'Season', 'Episode', 'StartTime', 'EndTime'],\n",
      "        num_rows: 1109\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Sr No.', 'Utterance', 'Speaker', 'Emotion', 'Sentiment', 'Dialogue_ID', 'Utterance_ID', 'Season', 'Episode', 'StartTime', 'EndTime'],\n",
      "        num_rows: 2610\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parents[0]\n",
    "MELD_ROOT = PROJECT_ROOT / \"data\" / \"raw\" / \"meld\"\n",
    "\n",
    "train = next(MELD_ROOT.rglob(\"train_sent_emo.csv\"))\n",
    "dev   = next(MELD_ROOT.rglob(\"dev_sent_emo.csv\"))\n",
    "test  = next(MELD_ROOT.rglob(\"test_sent_emo.csv\"))\n",
    "\n",
    "meld = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\n",
    "        \"train\": str(train),\n",
    "        \"validation\": str(dev),\n",
    "        \"test\": str(test),\n",
    "    }\n",
    ")\n",
    "\n",
    "meld.save_to_disk(PROJECT_ROOT / \"data\" / \"processed\" / \"meld\")\n",
    "print(meld)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9f06d",
   "metadata": {},
   "source": [
    "## Daily Dialog - Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "976c007a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Downloading UltraFeedback (parquet)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33397f684bdf4f738d82b553e7534299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d712ea76ae4593bd00eb0f23eb4650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce4f6580b0049cdb4881895c1bd8ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test_prefs-00000-of-00001.parquet:   0%|          | 0.00/7.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03e12b573ec4d64bf63840a28d849a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train_sft-00000-of-00001.parquet:   0%|          | 0.00/226M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0718e32d79543bbb3c3af9e8bc62a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train_prefs-00000-of-00001.parquet:   0%|          | 0.00/226M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69992926f7414929a82c93a7dc52aace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train_gen-00000-of-00001.parquet:   0%|          | 0.00/184M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129f9ea71dc942bbb81bbfb2c83dfad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "create_dataset.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd773a998924786a6e34444acc7f1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1be62fe40cf43e68c8d21e2f15ccc89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test_sft-00000-of-00001.parquet:   0%|          | 0.00/3.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cd19347419426a9a2a1f79fbc52ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test_gen-00000-of-00001.parquet:   0%|          | 0.00/3.02M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Loading local parquet files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e524bd84e6f457ba148ddce6eeb8250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6f248c60a546e5a163e48470257eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f023522e1244a7b3ff002e1189c7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/61135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e3fadafd6a4dc995a519b8e53258ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] UltraFeedback loaded and saved to: /root/workspace/agentic-nlp-rl/data/processed/ultrafeedback\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 61135\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path.cwd().parents[0]\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\" / \"ultrafeedback\"\n",
    "OUT_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"ultrafeedback\"\n",
    "\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"[+] Downloading UltraFeedback (parquet)...\")\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"HuggingFaceH4/ultrafeedback_binarized\",\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=RAW_DIR,\n",
    ")\n",
    "\n",
    "print(\"[+] Loading local parquet files...\")\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"parquet\",\n",
    "    data_files={\n",
    "        \"train\": str(next(RAW_DIR.rglob(\"train*.parquet\"))),\n",
    "        \"test\": str(next(RAW_DIR.rglob(\"test*.parquet\"))),\n",
    "    },\n",
    ")\n",
    "\n",
    "dataset.save_to_disk(OUT_DIR)\n",
    "\n",
    "print(\"[✓] UltraFeedback loaded and saved to:\", OUT_DIR)\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7995e633",
   "metadata": {},
   "source": [
    "## ALFWorld (Language + Embodied RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fa83ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ALFWorld...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/root/workspace/agentic-nlp-rl/data/raw/alfworld'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALFWorld downloaded to /root/workspace/agentic-nlp-rl/data/raw/alfworld\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading ALFWorld...\")\n",
    "\n",
    "if not os.listdir(PATHS[\"alfworld\"]):\n",
    "    subprocess.run([\n",
    "        \"git\", \"clone\",\n",
    "        \"https://github.com/alfworld/alfworld.git\",\n",
    "        PATHS[\"alfworld\"]\n",
    "    ], check=True)\n",
    "\n",
    "print(\"ALFWorld downloaded to\", PATHS[\"alfworld\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff71aa",
   "metadata": {},
   "source": [
    "## ScienceWorld (Text-Based Scientific RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd193d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ScienceWorld...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/root/workspace/agentic-nlp-rl/data/raw/scienceworld'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScienceWorld downloaded to /root/workspace/agentic-nlp-rl/data/raw/scienceworld\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading ScienceWorld...\")\n",
    "\n",
    "if not os.listdir(PATHS[\"scienceworld\"]):\n",
    "    subprocess.run([\n",
    "        \"git\", \"clone\",\n",
    "        \"https://github.com/allenai/scienceworld.git\",\n",
    "        PATHS[\"scienceworld\"]\n",
    "    ], check=True)\n",
    "\n",
    "print(\"ScienceWorld downloaded to\", PATHS[\"scienceworld\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70950f4",
   "metadata": {},
   "source": [
    "## TextWorld (Text-Based RL Environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a55dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing TextWorld...\n",
      "Requirement already satisfied: textworld in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from textworld) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.17.1 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from textworld) (4.67.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from textworld) (2.0.0)\n",
      "Requirement already satisfied: networkx>=2 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from textworld) (3.6.1)\n",
      "Requirement already satisfied: more_itertools in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from textworld) (10.8.0)\n",
      "Requirement already satisfied: tatsu==5.8.3 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from textworld) (5.8.3)\n",
      "Requirement already satisfied: hashids>=1.2.0 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from textworld) (1.3.1)\n",
      "Requirement already satisfied: jericho>=3.3.0 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from textworld) (3.3.1)\n",
      "Requirement already satisfied: mementos>=1.3.1 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from textworld) (1.3.1)\n",
      "Requirement already satisfied: termcolor in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from textworld) (3.3.0)\n",
      "Requirement already satisfied: prompt_toolkit in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from textworld) (3.0.52)\n",
      "Requirement already satisfied: pycparser in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from cffi>=1.0.0->textworld) (2.23)\n",
      "Requirement already satisfied: spacy>=2.1.0 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from jericho>=3.3.0->textworld) (3.8.11)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (0.21.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from spacy>=2.1.0->jericho>=3.3.0->textworld) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.0->jericho>=3.3.0->textworld) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.0->jericho>=3.3.0->textworld) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.0->jericho>=3.3.0->textworld) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.0->jericho>=3.3.0->textworld) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (2026.1.4)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy>=2.1.0->jericho>=3.3.0->textworld) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy>=2.1.0->jericho>=3.3.0->textworld) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from typer-slim<1.0.0,>=0.3.0->spacy>=2.1.0->jericho>=3.3.0->textworld) (8.3.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from weasel<0.5.0,>=0.4.2->spacy>=2.1.0->jericho>=3.3.0->textworld) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from weasel<0.5.0,>=0.4.2->spacy>=2.1.0->jericho>=3.3.0->textworld) (7.5.0)\n",
      "Requirement already satisfied: wrapt in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy>=2.1.0->jericho>=3.3.0->textworld) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from jinja2->spacy>=2.1.0->jericho>=3.3.0->textworld) (3.0.3)\n",
      "Requirement already satisfied: wcwidth in /opt/miniconda/envs/agentic/lib/python3.11/site-packages (from prompt_toolkit->textworld) (0.2.14)\n",
      "TextWorld installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "print(\"Installing TextWorld...\")\n",
    "\n",
    "subprocess.run(\n",
    "    [\"pip\", \"install\", \"textworld\"],\n",
    "    check=True\n",
    ")\n",
    "\n",
    "print(\"TextWorld installed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf10785",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93eb6ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALFWORLD:\n",
      "/root/workspace/agentic-nlp-rl/data/raw/alfworld\n",
      "\n",
      "MELD:\n",
      "/root/workspace/agentic-nlp-rl/data/raw/meld\n",
      "\n",
      "MPDD:\n",
      "/root/workspace/agentic-nlp-rl/data/raw/mpdd\n",
      "\n",
      "SCIENCEWORLD:\n",
      "/root/workspace/agentic-nlp-rl/data/raw/scienceworld\n",
      "\n",
      "TEXTWORLD:\n",
      "/root/workspace/agentic-nlp-rl/data/raw/textworld\n"
     ]
    }
   ],
   "source": [
    "for name, path in DATASETS.items():\n",
    "    print(f\"\\n{name.upper()}:\")\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        print(root)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d476e54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MELD root: /root/workspace/agentic-nlp-rl/data/raw/meld\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parents[0]\n",
    "meld_root = PROJECT_ROOT / \"data\" / \"raw\" / \"meld\"\n",
    "\n",
    "print(\"MELD root:\", meld_root)\n",
    "for path in meld_root.rglob(\"*.csv\"):\n",
    "    print(path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
